\section{Vector Spaces}

\paragraph{Motivation for Vector Spaces}
Vector spaces are a natural and important generalisation of 
\(\mathbb{R}^n\). It is natural to consider them whenever
it is possible to add objects and multiply them by scalars.

It may be convenient to consider a field \(\mathbb{F}\) as a vector
space over one of its subfields.

\paragraph{Definition of Vector Spaces}
Let \(\mathbb{F}\) be a field.
Then, a vector space over a field \(\mathbb{F}\) consists of an abelian
group \((V, +)\) and, a function from \(\mathbb{F}\times V \to V\) called
scalar multiplication and written as \(\alpha V\) where the following
properties hold.
\begin{enumerate}
    \item \textbf{Associativity over scalar multiplication:}
    \(\alpha (\beta v) = (\alpha\beta)v\)
    for all \(v\in V\), \(\alpha, \beta \in \mathbb{F}\)
    \item \textbf{Existence of 1:} \(1v = v\) for all \(v\in V\)
    \item \textbf{Distributivity of scalar multiplication over addition:}
    \(\alpha(u + v) = \alpha u + \alpha v\)
    for all \(u, v \in V, \alpha \in \mathbb{F}\)
    \item \textbf{Distributivity of addition over scalar multiplication:}
    \((\alpha+\beta)u = \alpha u + \beta u\)
\end{enumerate}



\paragraph{Properties and Notation for Vector Spaces}
\(\vec{dsdfa}\)
\begin{enumerate}
    \item Note that there are actually a total of ten axioms that exist.
    There is the four mentioned above, closure under scalar multiplication
    and, five that are inherited from the abelian group.
    \item Addition in \(V\) is called \textit{vector addition}
    to separate it from addition in \(\mathbb{F}\).
    \item \(V\) cannot be empty since it is a group.
    \item Bold face letters \(\vx, \vy, \vz\) may be used instead of \(x, y, z\),
    to denote vectors. More specifically, the identify of \((V, +)\)
    is denoted at \(\zero\) rather than the \( 0 \)
    that denotes a scalar in \(\mathbb{F}\).
    \item All the results from chapter 1 such as uniqueness of zero,
    negatives cancellation, \dots all apply for vector addition.
\end{enumerate}

\paragraph{Results on Combining Vectors Addition and Scalar}
Let \(V\) be a vector space over a field \(\mathbb{F}\).
Then for all \(\vu, \vv,\vw \in V\) and \(\lambda \in \mathbb{F}\),
\begin{enumerate}
    \item \(0 v = \zero \) and \(\lambda \zero = \zero\),
    \item \((-1)\vv = -\vv\),
    \item \(\lambda\vv = \zero \) implies either,
    \(\lambda = 0\) or \(\vv = 0\)
    \item If \(\lambda\vv = \lambda\vw\) where \(\lambda\neq 0\),
    then, \(\vv = \vw\).
\end{enumerate}

\subsection{Standard Examples of Vector Spaces}

\paragraph{The space \(\mathbb{F}^n\) over \(\mathbb{F}\)}
The set \(\mathbb{F}^n\) contains all \(n\)-tuples of elements of
\(\mathbb{F}\).
That is,
\[
    \mathbb{F}^n =
    \left\{ 
        \begin{pmatrix}
            \alpha_1 \\ \vdots \\ \alpha_n
        \end{pmatrix}
    \right\}
    :
    \alpha_i \in \mathbb{F}
\]

Let \(\vx = (\alpha_i)_{1\leq i \leq n}\)
and \(\vy = (\beta_i)_{1\leq i \leq n}\) be elements of \(\mathbb{F}\).
Then, vector addition is defined as
\[
        \vx + \vy = (\alpha_i + \beta_i)_{1\leq i \leq n}.
\]

Likewise, scalar multiplication on \(\mathbb{F}^n\) is defined as
\[
    \lambda\vx = (\lambda \vx_i)_{1 \leq i \leq n}.
\]

\paragraph{Geometric Vectors}
Geometric vectors are ordered pairs of points in \(\mathbb{R}^n\)
joined by label arrows. That is, they have direction and length.
These may be added by placing head to tail where, scalar multiplication
refers to increasing the length of the vector by a scalar value.

These vectors however, do not form a vector space. To do so, we define two
geometric vectors to be equivalent if one is a translation of the other.
Then, the set of equivalence classes of geometric vectors is a vector space.
That is, we do not care about the position of the geometric vector,
only its magnitude and direction.

\paragraph{Matrices}
For positive integers \(p, q\) the set \(M_{p, q}(\mathbb{F})\)
is the set of \(p\times q\) matrices with elements from \(F\).
Then, \(M_{p, q}\) is a vector space over \(\mathbb{F}\)
where vector addition and multiplication by a scalar are defined
by adding each corresponding element or, multiplying each element
by a the scalar.

\paragraph{Polynomials}
The set of all polynomials with coefficients in \(\mathbb{F}\)
denoted by \(\mathcal{P}(\mathbb{F})\) is a vector space over
\(\mathbb{F}\) with
\begin{align*}
    (f+g)(x) &= f(x) + g(x) && \text{ for all } x\in \mathbb{F}, \\
    (\lambda f)(x) &= \lambda f(x) && \text{ for all } \lambda, x\in \mathbb{F}.
\end{align*}

We may denote \(\mathcal{P}(\mathbb{F})\) to be the set of all polynomials
with degree \(n\) or less. This is also a vector space over \(\mathbb{F}\).

\paragraph{Function Spaces}
Let \(X\) be a non-empty set and \(\mathbb{F}\) be a field.
Then,
\[
    \mathcal{F}[X] = \left\{ f : X\to \mathbb{F} \right\}
\]
where \(\mathcal{F}[X]\)is a vector space of \(F\) representing the
set of all functions.
We must define
\begin{enumerate}
    \item The zero to be the zero function \(x \to 0\) for all \(x\in X\)
    \item \((f + g)(x) = f(x) + g(x)\) for all \(x\in X\)
    \item \((\lambda f)(x) = \lambda(f(x))\) for all \(x\in X\)
\end{enumerate}

Note that here, we use \(\mathcal{F}\) to correspond with \(\mathbb{F}\).
If we were however using \(\mathbb{R}\) as a field then, we may instead
prefer to use \(\mathcal{R}\) for the set of all functions instead.
Similarly, we extend this for \(\mathcal{Q}\) too.

\subsection{Subspaces}

\paragraph{Defining Vector Subspaces}
If \(V\) is a vector space over \(\mathbb{F}\) and \(U\subseteq V\)
then, \(U\) is a subspace of \(V\), denoted as \(U \leq V\)
if, it is a vector space over \(\mathbb{F}\) with the same addition
and scalar multiplication as \(V\).

Observe that every vector space has \(\{0\}\) (the trivial subspace)
and itself as subspaces.

\paragraph{Subspace Lemma}
To check if \(U\) is a subspace of a vector space \(V\), is is sufficient
to just check for closure under addition and scalar multiplication.
These conditions may be combined such that \(U\) is a subspace of
\(V\) if and only if, for all \(\alpha \in \mathbb{F}\),
\(\vu, \vv \in U\), \(\alpha\vu + \vv \in \mathbb{F}\).

The other axioms may be inherited from \(V\) and it must be ensured that
\(\zero \in U\).

\paragraph{All subspaces of \(\mathbb{R}^3\)}
Trivially, every subspace must have \(\zero\) as an element so,
it is clear that \(\{\zero\} \leq \mathbb{R}^3\).
Then, the remaining subspaces must be of the form
\[
    \{\lambda \va : \lambda\in \mathbb{R} \}
    \quad \text{\quad or \quad} \quad
    \{\lambda \va + \mu \vb: \lambda, \mu \in \mathbb{R} \}.
    \quad \text{\quad or \quad} \quad
    \{\lambda \va + \mu \vb + v\vc: \lambda, \mu, v\in \mathbb{R} \}.
\]
That is, any line or plane through the origin or, all of \(\mathbb{R}^3\).

\paragraph{Subspace Examples}
\begin{itemize}
    \item In \(M_{p, p}\), the set of symmetric matrices is a subspace.
    \item Let \(X\)  be any set and \(Y\subseteq X\)
    The set \(
        \{
            f\in \mathcal{F}[X] : f(y) = 0 \forall y\in Y
        \}
    \) is a subspace of \(\mathcal{F}\).
    \item For any interval \(I\subseteq \mathbb{R}\) the set \(C(I)\)
    of continuous functions on \(I\) is a subspace of \(\mathcal{R}(I)\).
    Similarly, if \(I\) is open, the set of differential functions,
    continuously differentiable, twice differentiable, \(\dots\), 
    are a subspace of \(I\), each one being a subspace of the previous.
\end{itemize}

\paragraph{Sub-Vector space but not Subspace}
It is entirely possible to have a subset of a vector space be a vector space
but, not a subspace. A usual example is \(\mathbb{R}^{+}\) where multiplication
is used as addition. This set is a subset of \(\mathbb{R}\) and a vector
space but it is not a subspace.

Also consider, \(\mathbb{C}^2\) as a vector space and let and let 
\(V = \{
    \vv \in \mathbb{C}^2 : v_1 \in \mathbb{R}
\}\).

Here, \(V\) is not a subspace of \(\mathbb{C}^2\) over \(\mathbb{C}\).
This stems from the fact that over \(\mathbb{C}\), complex scalars are
allowed. However, we could consider \(\mathbb{C}^2\) as a vector space over
\(\mathbb{R}\) such that we are only allowed to multiply by scalars in
\(\mathbb{R}\) but, still allowed complex elements in the vector.


\subsection{Linear Combinations, Spans and Independence}

\paragraph{Linear Combinations}
Let \(V\) be a vector space over \(\mathbb{F}\). A (finite)
linear combination of vectors \(\vv_1, \vv_2, \dots, \vv_n\) in \(V\)
is any vector that for scalars \(a_k\), may be expressed as
\[
    \alpha_1\vv_1 + \alpha_2\vv_2 + \dots + \alpha_n\vv_n;
\]

\paragraph{Span}
If \(S\) is a subset of \(V\) then, the space of \(S\) is
\[
    \span(S) = \{\text{all finite linear combinatons of vectors in \(S\)}\}.
\]
If \(\span(S) = V\) then, \(S\) is a spanning set of \(V\). That is,
\(S\) spans \(V\).
It may also be natural to say that \(V\) generates \(S\).

\paragraph{Spans as Subspaces}
If \(S\) is a non-empty subset of a vector space \(V\) then,
\(\span(S)\) is a subspace of \(V\).
\begin{itemize}
    \item The zero element trivially exists and, the span is non-empty as
    \(S\) is non-empty.
    \item For \(\vv, \vw \in S\), \(\lambda\vv + \vw\) is a linear combination
    of two linear combinations of \(S\) which makes it a linear combination of
    element in \(V\) and thus, is in \(\span (S)\).
\end{itemize}

\paragraph{Linear Independence}
A subset \(S\) of a vector space \(V\) is linearly independent
if for all vectors \(\vv_1, \vv_2, \dots ,\vv_n\in S\), (where \(n\geq 1\)),
with \(\alpha_i in \mathbb{F}\),
\[
    \alpha_1 \vv_1 + \alpha_2 \vv_2 + \dots + \alpha_n \vv_n = 0,
\]
implies that \(a_i = 0\)  for all \(i = 1\dots n\).
That is, the solution to the above equation is unique.

\paragraph{Linear Dependence}
A set \(S = \{\vv_1, \dots \vv_n\}\) is  linearly dependent in \(V\) then,
there exists an \(i, 2\leq i \leq n\) 
such that 
\[
    \vv_i = \sum_{j=1}^{i-1} \beta_j \vv_j.
\]

\paragraph{Properties and Theorems for Linear Dependence}
\begin{itemize}
    \item Any subset of a linearly independent set is linearly independent,
    \item If \(\vv \in \span(S)\) then \(S\cap \{\vv\}\) is linearly dependent,
    \item If \(S\) is linearly independent and \(S\cup \{\vv\}\)
    is linearly dependent then, \(v\in \span(S)\),
    \item If \(S_1 \subseteq S_2\) then \(\span(S_1) \subseteq span(S_2)\),
    \item If \(S_1 \subseteq \span(S_2)\) then
    \(\span(S_1) \subseteq span(S_2)\),
    \item \(\span(S\cup \{\vv\}) = span(S)\) if and only if
    \(\vv \in \span(S)\).
    \item If \(S\) is linearly dependent then, there exists \(\vv\in S\)
    such that \(S\backslash\{\vv\} = \span{S}\).
    \item In \(\mathbb{F}^n\), if \(P\in GL(p, \mathbb{F})\) is also
    an invertible matrix and \(\{\vv_i\}\) is a linearly independent set
    then, \(\{P\vv_i\}\) is also linearly independent. This may be proved
    by contradiction.
\end{itemize}
